# -*- coding: utf-8 -*-
"""data_perproation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fwKzS1WXjplNEankGtbv3-v59efXgJIQ

Task 1: Data Perproation
"""

import pandas as pd
import numpy as np

path = '/content/Telco_Customer_Churn_Dataset  (3).csv'
df = pd.read_csv(path)
print("Total Customers: ", len(df))
print("Total Row & Columns: ", df.shape)

df.head(5)

df.info()

df.describe()

df.dtypes

df['SeniorCitizen'].head(5)

df['SeniorCitizen'] = df['SeniorCitizen'].map({1: 'Yes', 0: 'No'})
df['SeniorCitizen'].head(5)

print(df['TotalCharges'].dtype)  # Should be float64
print(df['TotalCharges'].isna().sum())  # Number of NaNs introduced

print(df.dtypes.value_counts())

"""Data Cleaning"""

df.isnull().sum()

def clean_dataframe(df):
  def clean_column(col):
    if col.dtype == 'object':
      # Strip whitespace and replace empty strings with NaN
      return col.str.strip().replace('', np.nan)
    elif pd.api.types.is_numeric_dtype(col):
      # Replace infinite values with NaN
      return col.replace([np.inf, -np.inf], np.nan)
    else:
      return col  # Leave other types untouched (e.g., datetime, bool)

  return df.apply(clean_column)
df = clean_dataframe(df)

# Convert to float
df['TotalCharges'] = df['TotalCharges'].astype(float)
df['TotalCharges'].dtypes

"""Check Duplicate"""

df[df.duplicated()]

df.drop_duplicates()

df.isnull().sum()

df['TotalCharges'].isnull().sum()

problem_rows = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isna()]
print(problem_rows[['customerID', 'TotalCharges']])

df['TotalCharges'].median()

df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())

df.isnull().sum()

df.columns

# Create a copy to preserve original
df_encoded = df.copy()

# Drop customerID if present
customer_ids = df_encoded['customerID']
df_encoded.drop('customerID', axis=1, inplace=True)

df_encoded.columns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Create TenureGroup before encoding or splitting
max_tenure = df_encoded['tenure'].max()
last_bin = max(74, max_tenure + 1)
df_encoded['TenureGroup'] = pd.cut(df_encoded['tenure'], bins=[0, 12, 24, 36, 48, 60, 73, last_bin],
                           labels=['0-12', '13-24', '25-36', '37-48', '49-60', '61-73', '74+'], right = False)

# Encode binary categorical columns

binary_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']
le = LabelEncoder()
for col in binary_cols:
    df_encoded[col] = le.fit_transform(df_encoded[col])

# One-hot encode remaining object columns
remaining_cat_cols = df_encoded.select_dtypes(include='object').columns.tolist()
df_encoded = pd.get_dummies(df_encoded, columns=remaining_cat_cols, drop_first=True)

# Split dataset
def split_dataset(df_encoded, target_column = 'Churn', drop_columns = None, test_size=0.2, random_state=42):
  X = df_encoded.drop(drop_columns, axis=1)
  y = df_encoded[target_column]
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
  return X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = split_dataset(df_encoded, drop_columns=['Churn','TenureGroup'])